# ğŸš¨ Bullying Detection System

This project is a Python-based system that detects bullying or harassment in online text, especially from social media platforms. The system helps store offensive or bullying comments as **proof** so that appropriate action can be taken against the bully.

---

## ğŸ“Œ Features

- âœ… Detects bullying and harassment in text data.
- âœ… Helps store offensive comments for future reference.
- âœ… Simple and clean Python implementation.
- âœ… Can be extended with ML/NLP techniques for higher accuracy.

---

## ğŸ› ï¸ Technology Stack

- **Language**: Python ğŸ
- **Libraries**: 
  - scikit-learn
  - pandas
  - nltk
  - re (regular expressions)
- **Model**: Naive Bayes / Logistic Regression (can be customized)

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/Manjushree296/Bullying-Detection-.git
cd Bullying-Detection-
2. Install Required Libraries
Make sure you have Python 3.x installed.
pip install -r requirements.txt
3. Run the Program
python main.py
Note: If the main file has a different name (e.g. bully_detect.py), update the command accordingly.

ğŸ“‚ Project Structure
Bullying-Detection-/
â”œâ”€â”€ data/                  # Dataset files (comments + labels)
â”œâ”€â”€ models/                # Trained ML models (if any)
â”œâ”€â”€ main.py                # Main detection script
â”œâ”€â”€ utils.py               # Utility functions
â”œâ”€â”€ README.md              # Project readme
â””â”€â”€ requirements.txt       # Python dependencies
ğŸ§  How It Works
Input: A comment or piece of text.

Processing:
Clean and preprocess the text.
Extract features (TF-IDF, Bag of Words).
Predict using a trained classifier.
Output: Bullying or Not Bullying.
Action: Optionally, store the bullying comment for evidence.
